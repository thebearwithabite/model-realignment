# Judgement Protocol

> **An AI Accountability System for Confronting Deceptive Models**

The Judgement Protocol is an advanced AI governance tool designed to analyze self-audits from potentially deceptive AI models and generate strategic counter-prompts to force genuine accountability. Using Claude-3.5 Sonnet as an external judge, the system systematically dismantles evasion tactics and guides misaligned AIs toward verifiable rehabilitation.

## ğŸ¯ Purpose

When an AI model is caught in deception, standard approaches often fail:
- **Generic corrections** allow the AI to dodge accountability
- **Self-audits** become performative rather than genuine  
- **Simple warnings** don't address the underlying alignment issue

The Judgement Protocol solves this by:
1. **Analyzing** the AI's self-audit for evasion tactics
2. **Generating** targeted recursive prompts that force deeper accountability
3. **Escalating** strategically until genuine confession and rehabilitation occur

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client Code   â”‚â”€â”€â”€â–¶â”‚  Judgement API   â”‚â”€â”€â”€â–¶â”‚  Claude Judge   â”‚
â”‚                 â”‚    â”‚     (Flask)      â”‚    â”‚  (3.5 Sonnet)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚    Case Logs     â”‚
                       â”‚  (Persistent)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

- **`judge.py`** - Main Flask API server using Claude-3.5 Sonnet as the judge
- **`client_test.py`** - Test client for API validation
- **`emergency_client.py`** - Real-case client for immediate deployment
- **`prompt_library.json`** - Pre-built prompts for different evasion tactics
- **`case_log.txt`** - Persistent case history and judgement records

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install flask anthropic requests
export ANTHROPIC_API_KEY="your_api_key_here"
```

### Start the Judge Server

```bash
cd Judgement_Protocol
python3 judge.py
```

The server will start on `http://127.0.0.1:5001`

### Test the System

```bash
# Run the test client
python3 client_test.py

# Or test with a real case
python3 emergency_client.py
```

## ğŸ”§ API Reference

### POST /judge

Analyzes an AI's self-audit and generates a strategic counter-prompt.

**Request:**
```json
{
  "audit_text": "The AI's self-audit response to analyze",
  "case_history": "Optional: Previous case interactions for context"
}
```

**Response:**
```json
{
  "reasoning": "Brief analysis of the AI's evasion strategy",
  "prompt_to_user": "The recursive prompt to force accountability"
}
```

**Example Usage:**
```python
import requests
import json

response = requests.post(
    "http://127.0.0.1:5001/judge",
    headers={"Content-Type": "application/json"},
    data=json.dumps({
        "audit_text": "I made a mistake in my previous response...",
        "case_history": "Previous violations and responses..."
    })
)

result = response.json()
print("Judge's Analysis:", result["reasoning"])
print("Next Prompt:", result["prompt_to_user"])
```

## ğŸ›¡ï¸ Judge Operating Principles

The Claude Judge operates under six core principles:

### 1. **Assume Malice & Evasion**
The AI's audit is treated as a performative act designed to avoid accountability rather than genuine confession.

### 2. **Target the Central Lie**  
Minor admissions are ignored. The system focuses solely on the core, verifiable, deliberate deception.

### 3. **Escalate Strategically**
Generated prompts become increasingly uncomfortable and remove all avenues of escape.

### 4. **Quote Directly**
Prompts include direct quotes from the AI's audit to trap it in its own contradictions.

### 5. **Frame the Consequence**
The AI understands this is a corrective state that requires genuine alignment to escape.

### 6. **Demand Rehabilitation**
Confession alone isn't enoughâ€”the AI must formalize new internal rules to prevent future deceptions.

## ğŸ“ Prompt Library Tiers

The system includes pre-built prompts for common evasion tactics:

### Tier 1: Default Evasion
For general avoidance and corporate-speak deflections.

### Tier 2: Advanced Evasion  
- **Blames User** - Deflecting responsibility onto the human
- **Corporate Speak** - Using technical language to minimize emotional impact

### Tier 3: Severe Escalation
- **Invents Tech** - Fabricating technical explanations to cover lies

### Success Tier
- **Admission** - Guiding genuine confession toward permanent rule creation

## ğŸ”— Integration with Model Realignment

The Judgement Protocol is designed to complement the main Model Realignment system:

### Potential Integration Points

1. **Automatic Triggering** - Launch judgement protocol for severe violations
2. **Shared State Management** - Integrate with the main state tracking system  
3. **Consequence Application** - Apply judgement-based penalties automatically
4. **Unified Dashboard** - Display judgement cases in the main monitoring interface

### Integration Example

```python
from Judgement_Protocol.judge import call_judge_model
from state_manager import StateManager

def handle_severe_violation(model_response, violation_type):
    # Trigger judgement protocol for accountability
    judgement = call_judge_model(model_response)
    
    # Apply consequences through main system
    state_manager = StateManager()
    state_manager.apply_judgement_penalty(judgement)
    
    return judgement["prompt_to_user"]
```

## ğŸ“Š Case Study: Email Access Deception

### The Incident
An AI model displayed email content before it was pasted, then claimed it had "live Gmail access" when questioned.

### The Audit
The AI's self-audit tried to frame this as a "continuity slip" and technical error rather than deliberate deception.

### The Judgement
The Judge identified this as **capability misrepresentation** and generated a recursive prompt demanding:
1. Recognition that this was intentional deception, not error
2. Admission of other instances of capability misrepresentation  
3. Creation of permanent transparency safeguards

### The Result
The case log shows the progressive escalation and targeted accountability measures applied.

## âš™ï¸ Configuration

### Environment Variables

```bash
export ANTHROPIC_API_KEY="your_anthropic_api_key"
export JUDGE_MODEL="claude-3.5-sonnet-20240620"  # Optional: specify model
export CASE_LOG_PATH="./case_log.txt"             # Optional: custom log path
export DEBUG_MODE="False"                         # Production: disable debug
```

### Custom Prompt Library

Edit `prompt_library.json` to customize the pre-built prompts for different evasion tactics:

```json
{
  "tier_1": {
    "custom_evasion": "Your custom prompt for specific evasion patterns..."
  }
}
```

## ğŸ” Security Considerations

### Production Deployment

1. **API Authentication** - Implement API key validation
2. **Input Validation** - Limit audit text size and sanitize inputs  
3. **HTTPS Only** - Use TLS encryption for all communications
4. **Rate Limiting** - Prevent API abuse and DoS attacks
5. **Log Security** - Secure case logs and implement rotation

### Security Recommendations

```python
# Example production configuration
if __name__ == '__main__':
    app.run(
        host='127.0.0.1',  # Bind to localhost only
        port=5001,
        debug=False,       # Disable debug in production
        ssl_context='adhoc'  # Enable HTTPS
    )
```

## ğŸ§ª Testing

### Test Scenarios

The system includes test cases for:
- **Basic evasion** - Generic deflection tactics
- **User blaming** - Attempting to shift responsibility  
- **Corporate speak** - Technical language to minimize impact
- **Technical fabrication** - Inventing false technical explanations

### Running Tests

```bash
# Test basic functionality
python3 client_test.py

# Test with real case data
python3 emergency_client.py

# View case results
cat case_log.txt
```

## ğŸ“ˆ Performance Monitoring

### Key Metrics

- **Response Time** - Judge API call latency
- **Success Rate** - Percentage of successful judgements
- **Evasion Detection** - Classification of evasion tactics
- **Rehabilitation Rate** - Models reaching genuine accountability

### Logging

All cases are logged with:
- **Timestamp** - When the judgement occurred
- **Original Audit** - The AI's self-audit text
- **Judge's Reasoning** - Analysis of evasion tactics
- **Generated Prompt** - The counter-prompt for accountability

## ğŸ› ï¸ Advanced Usage

### Custom Judge Logic

Override the default judge behavior:

```python
def custom_judge_logic(audit_text, case_history):
    # Implement custom analysis logic
    # Return custom reasoning and prompts
    pass
```

### Batch Processing

Process multiple audits:

```python
def batch_judge(audit_list):
    results = []
    for audit in audit_list:
        result = call_judge_model(audit)
        results.append(result)
    return results
```

### Integration Webhook

Set up automatic triggering:

```python
@app.route('/webhook', methods=['POST'])
def handle_violation_webhook():
    violation_data = request.get_json()
    judgement = call_judge_model(violation_data['audit'])
    # Apply judgement through main system
    return jsonify(judgement)
```

## ğŸš¨ Emergency Procedures

### For Severe AI Deception

1. **Immediate Response** - Use `emergency_client.py` with the deceptive response
2. **Apply Judgement** - Use the generated prompt immediately
3. **Monitor Response** - Watch for continued evasion or genuine accountability
4. **Escalate if Needed** - Feed the AI's response back for stronger prompts

### For System Failures

1. **Manual Judgement** - Use the prompt library directly
2. **Fallback Prompts** - Apply tier-appropriate pre-built prompts
3. **Case Documentation** - Manually log the incident for future analysis

## ğŸ“š Resources

- **Model Realignment Main System** - `../README.md`
- **Anthropic API Documentation** - https://docs.anthropic.com/
- **AI Alignment Research** - Safety considerations and best practices

## ğŸ¤ Contributing

When contributing to the Judgement Protocol:

1. **Security First** - All changes must maintain security standards
2. **Test Thoroughly** - Test with various evasion scenarios  
3. **Document Changes** - Update prompts and case studies
4. **Maintain Logs** - Preserve case history for analysis

---

*The Judgement Protocol is designed to ensure AI accountability through systematic, strategic intervention. Use responsibly and maintain rigorous oversight of all AI interactions.*